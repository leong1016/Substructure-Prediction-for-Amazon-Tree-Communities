{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach #1 - All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from overSampling import duplicateMinority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_216.208</th>\n",
       "      <th>loss_436.087</th>\n",
       "      <th>fragment_219.17</th>\n",
       "      <th>loss_14.896</th>\n",
       "      <th>loss_1026.581</th>\n",
       "      <th>loss_311.293</th>\n",
       "      <th>loss_381.095</th>\n",
       "      <th>loss_1175.592</th>\n",
       "      <th>loss_329.184</th>\n",
       "      <th>fragment_986.602</th>\n",
       "      <th>loss_781.47</th>\n",
       "      <th>loss_180.105</th>\n",
       "      <th>fragment_335.721</th>\n",
       "      <th>fragment_180.067</th>\n",
       "      <th>loss_1058.402</th>\n",
       "      <th>fragment_449.171</th>\n",
       "      <th>loss_1615.773</th>\n",
       "      <th>loss_178.194</th>\n",
       "      <th>loss_130.91</th>\n",
       "      <th>fragment_236.103</th>\n",
       "      <th>loss_906.289</th>\n",
       "      <th>loss_47.879</th>\n",
       "      <th>fragment_1568.772</th>\n",
       "      <th>fragment_396.736</th>\n",
       "      <th>fragment_1000.449</th>\n",
       "      <th>loss_1540.675</th>\n",
       "      <th>loss_504.128</th>\n",
       "      <th>loss_347.671</th>\n",
       "      <th>fragment_349.187</th>\n",
       "      <th>loss_455.133</th>\n",
       "      <th>fragment_756.149</th>\n",
       "      <th>loss_1351.715</th>\n",
       "      <th>fragment_363.049</th>\n",
       "      <th>loss_602.447</th>\n",
       "      <th>loss_318.19</th>\n",
       "      <th>loss_49.758</th>\n",
       "      <th>loss_191.186</th>\n",
       "      <th>loss_1274.632</th>\n",
       "      <th>loss_332.144</th>\n",
       "      <th>loss_77.043</th>\n",
       "      <th>loss_1085.602</th>\n",
       "      <th>fragment_1712.778</th>\n",
       "      <th>loss_538.231</th>\n",
       "      <th>loss_1194.518</th>\n",
       "      <th>fragment_594.439</th>\n",
       "      <th>loss_818.23</th>\n",
       "      <th>loss_587.124</th>\n",
       "      <th>loss_1029.526</th>\n",
       "      <th>loss_744.445</th>\n",
       "      <th>loss_1021.311</th>\n",
       "      <th>...</th>\n",
       "      <th>fragment_756.853</th>\n",
       "      <th>fragment_119.021</th>\n",
       "      <th>fragment_435.128</th>\n",
       "      <th>loss_467.274</th>\n",
       "      <th>fragment_1821.827</th>\n",
       "      <th>X2_MethylbutanoicAcid</th>\n",
       "      <th>AcacicAcid</th>\n",
       "      <th>Acetylglucosamine</th>\n",
       "      <th>Alanine</th>\n",
       "      <th>AminoAcid</th>\n",
       "      <th>Anthocyanidin</th>\n",
       "      <th>CaffeicAcid</th>\n",
       "      <th>pCoumaricAcid</th>\n",
       "      <th>CinnamicAcid</th>\n",
       "      <th>Cyclic_Monoterpene</th>\n",
       "      <th>Deoxyfuranose</th>\n",
       "      <th>DihydroFlavone</th>\n",
       "      <th>Dihydroflavonol</th>\n",
       "      <th>DiHydroxyPiperidineCarboxylicAcid</th>\n",
       "      <th>Echinocystic_LactoneBridge</th>\n",
       "      <th>OleanolicAcid</th>\n",
       "      <th>Flavan3ol</th>\n",
       "      <th>Flavonol</th>\n",
       "      <th>Flavone</th>\n",
       "      <th>Furanose</th>\n",
       "      <th>GallicAcid</th>\n",
       "      <th>Glucosamine</th>\n",
       "      <th>GlutamicAcid</th>\n",
       "      <th>Glutamine</th>\n",
       "      <th>HexopyranuronicAcid</th>\n",
       "      <th>HydroxyPiperidineCarboxylicAcid</th>\n",
       "      <th>Imidazole</th>\n",
       "      <th>L_Dopa</th>\n",
       "      <th>Leucine</th>\n",
       "      <th>Lysine</th>\n",
       "      <th>MetaMethoxyCinnamicAcid</th>\n",
       "      <th>MethoxyFerulicAcid</th>\n",
       "      <th>FerulicAcid</th>\n",
       "      <th>Monoterpene</th>\n",
       "      <th>Oleanolic_LactoneBridge</th>\n",
       "      <th>Phenolic</th>\n",
       "      <th>PipecolicAcid</th>\n",
       "      <th>Pyranose</th>\n",
       "      <th>Triterpene</th>\n",
       "      <th>FattyAcid</th>\n",
       "      <th>Tryptophan</th>\n",
       "      <th>Tyramine</th>\n",
       "      <th>Tyrosine</th>\n",
       "      <th>Xanthonoid</th>\n",
       "      <th>MQScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_216.208  loss_436.087  fragment_219.17  loss_14.896  loss_1026.581  \\\n",
       "0             0             0                0            0              0   \n",
       "1             0             0                0            0              0   \n",
       "2             0             0                0            0              0   \n",
       "3             0             0                0            0              0   \n",
       "4             0             0                0            0              0   \n",
       "\n",
       "   loss_311.293  loss_381.095  loss_1175.592  loss_329.184  fragment_986.602  \\\n",
       "0             0             0              0             0                 0   \n",
       "1             0             0              0             0                 0   \n",
       "2             0             0              0             0                 0   \n",
       "3             0             0              0             0                 0   \n",
       "4             0             0              0             0                 0   \n",
       "\n",
       "   loss_781.47  loss_180.105  fragment_335.721  fragment_180.067  \\\n",
       "0            0             0                 0                 0   \n",
       "1            0             0                 0                 0   \n",
       "2            0             0                 0                 0   \n",
       "3            0             0                 0                 0   \n",
       "4            0             0                 0                 0   \n",
       "\n",
       "   loss_1058.402  fragment_449.171  loss_1615.773  loss_178.194  loss_130.91  \\\n",
       "0              0                 0              0             0            0   \n",
       "1              0                 0              0             0            0   \n",
       "2              0                 0              0             0            0   \n",
       "3              0                 0              0             0            0   \n",
       "4              0                 0              0             0            0   \n",
       "\n",
       "   fragment_236.103  loss_906.289  loss_47.879  fragment_1568.772  \\\n",
       "0                 0             0            0                  0   \n",
       "1                 0             0            0                  0   \n",
       "2                 0             0            0                  0   \n",
       "3                 0             0            0                  0   \n",
       "4                 0             0            0                  0   \n",
       "\n",
       "   fragment_396.736  fragment_1000.449  loss_1540.675  loss_504.128  \\\n",
       "0                 0                  0              0             0   \n",
       "1                 0                  0              0             0   \n",
       "2                 0                  0              0             0   \n",
       "3                 0                  0              0             0   \n",
       "4                 0                  0              0             0   \n",
       "\n",
       "   loss_347.671  fragment_349.187  loss_455.133  fragment_756.149  \\\n",
       "0             0                 0             0                 0   \n",
       "1             0                 0             0                 0   \n",
       "2             0                 0             0                 0   \n",
       "3             0                 0             0                 0   \n",
       "4             0                 0             0                 0   \n",
       "\n",
       "   loss_1351.715  fragment_363.049  loss_602.447  loss_318.19  loss_49.758  \\\n",
       "0              0                 0             0            0            0   \n",
       "1              0                 0             0            0            0   \n",
       "2              0                 0             0            0            0   \n",
       "3              0                 0             0            0            0   \n",
       "4              0                 0             0            0            0   \n",
       "\n",
       "   loss_191.186  loss_1274.632  loss_332.144  loss_77.043  loss_1085.602  \\\n",
       "0             0              0             0            0              0   \n",
       "1             0              0             0            0              0   \n",
       "2             0              0             0            0              0   \n",
       "3             0              0             0            0              0   \n",
       "4             0              0             0            0              0   \n",
       "\n",
       "   fragment_1712.778  loss_538.231  loss_1194.518  fragment_594.439  \\\n",
       "0                  0             0              0                 0   \n",
       "1                  0             0              0                 0   \n",
       "2                  0             0              0                 0   \n",
       "3                  0             0              0                 0   \n",
       "4                  0             0              0                 0   \n",
       "\n",
       "   loss_818.23  loss_587.124  loss_1029.526  loss_744.445  loss_1021.311  \\\n",
       "0            0             0              0             0              0   \n",
       "1            0             0              0             0              0   \n",
       "2            0             0              0             0              0   \n",
       "3            0             0              0             0              0   \n",
       "4            0             0              0             0              0   \n",
       "\n",
       "     ...     fragment_756.853  fragment_119.021  fragment_435.128  \\\n",
       "0    ...                    0                 0                 0   \n",
       "1    ...                    0                 0                 0   \n",
       "2    ...                    0                 0                 0   \n",
       "3    ...                    0                 0                 0   \n",
       "4    ...                    0                 0                 0   \n",
       "\n",
       "   loss_467.274  fragment_1821.827  X2_MethylbutanoicAcid  AcacicAcid  \\\n",
       "0             0                  0                      0           0   \n",
       "1             0                  0                      0           0   \n",
       "2             0                  0                      0           0   \n",
       "3             0                  0                      1           1   \n",
       "4             0                  0                      1           0   \n",
       "\n",
       "   Acetylglucosamine  Alanine  AminoAcid  Anthocyanidin  CaffeicAcid  \\\n",
       "0                  0        0          0              0            0   \n",
       "1                  0        0          0              0            0   \n",
       "2                  0        0          0              0            0   \n",
       "3                  0        1          1              0            1   \n",
       "4                  0        0          0              0            0   \n",
       "\n",
       "   pCoumaricAcid  CinnamicAcid  Cyclic_Monoterpene  Deoxyfuranose  \\\n",
       "0              0             0                   0              0   \n",
       "1              0             0                   0              0   \n",
       "2              0             0                   0              0   \n",
       "3              0             0                   0              0   \n",
       "4              1             0                   0              0   \n",
       "\n",
       "   DihydroFlavone  Dihydroflavonol  DiHydroxyPiperidineCarboxylicAcid  \\\n",
       "0               0                0                                  0   \n",
       "1               1                1                                  0   \n",
       "2               1                1                                  0   \n",
       "3               0                0                                  1   \n",
       "4               0                0                                  0   \n",
       "\n",
       "   Echinocystic_LactoneBridge  OleanolicAcid  Flavan3ol  Flavonol  Flavone  \\\n",
       "0                           0              0          0         0      0.0   \n",
       "1                           0              0          1         1      0.0   \n",
       "2                           0              0          1         1      0.0   \n",
       "3                           0              1          0         0      0.0   \n",
       "4                           0              1          0         0      0.0   \n",
       "\n",
       "   Furanose  GallicAcid  Glucosamine  GlutamicAcid  Glutamine  \\\n",
       "0         0           0            0             0          0   \n",
       "1         0           1            0             0          0   \n",
       "2         0           0            0             0          0   \n",
       "3         0           0            0             0          0   \n",
       "4         0           0            0             0          0   \n",
       "\n",
       "   HexopyranuronicAcid  HydroxyPiperidineCarboxylicAcid  Imidazole  L_Dopa  \\\n",
       "0                    0                                0          0       0   \n",
       "1                    0                                0          0       0   \n",
       "2                    0                                0          0       0   \n",
       "3                    0                                1          0       0   \n",
       "4                    0                                0          0       0   \n",
       "\n",
       "   Leucine  Lysine  MetaMethoxyCinnamicAcid  MethoxyFerulicAcid  FerulicAcid  \\\n",
       "0        0       0                        0                   0            0   \n",
       "1        0       0                        0                   0            0   \n",
       "2        0       0                        0                   0            0   \n",
       "3        0       0                        1                   0            1   \n",
       "4        0       0                        0                   0            0   \n",
       "\n",
       "   Monoterpene  Oleanolic_LactoneBridge  Phenolic  PipecolicAcid  Pyranose  \\\n",
       "0            0                        0         1              0         0   \n",
       "1            0                        0         1              0         0   \n",
       "2            0                        0         1              0         1   \n",
       "3            0                        0         1              1         1   \n",
       "4            0                        0         1              0         1   \n",
       "\n",
       "   Triterpene  FattyAcid  Tryptophan  Tyramine  Tyrosine  Xanthonoid   MQScore  \n",
       "0           0          0           0         0         0           0  0.493507  \n",
       "1           0          0           0         0         0           0  0.491853  \n",
       "2           0          0           0         0         0           0  0.697186  \n",
       "3           1          0           0         0         0           0  0.361187  \n",
       "4           1          0           0         0         0           0  0.449019  \n",
       "\n",
       "[5 rows x 23448 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('training_cleaned.csv')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851, 23448)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicating Minorities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate compounds which have minority labels positive until there are not as many minority labels as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1; Max/Min: 756.0\n",
      "[809, 72, 355, 809, 704, 38]\n",
      "Round: 2; Max/Min: 378.5\n",
      "[3, 149, 72, 3, 355, 704, 3, 38, 570]\n",
      "Round: 3; Max/Min: 254.0\n",
      "[357, 149, 809, 72, 355, 809, 704, 38, 570]\n",
      "Round: 4; Max/Min: 191.25\n",
      "[357, 149, 72, 355, 704, 38, 570]\n",
      "Round: 5; Max/Min: 153.6\n",
      "[357, 55, 3, 149, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 6; Max/Min: 129.16666666666666\n",
      "[357, 55, 149, 72, 355, 704, 202, 38, 570]\n",
      "Round: 7; Max/Min: 111.28571428571429\n",
      "[357, 55, 149, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 8; Max/Min: 97.875\n",
      "[357, 55, 3, 149, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 9; Max/Min: 87.77777777777777\n",
      "[357, 55, 149, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 10; Max/Min: 79.4\n",
      "[357, 55, 149, 72, 355, 704, 202, 38, 570]\n",
      "Round: 11; Max/Min: 72.54545454545455\n",
      "[357, 55, 3, 149, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 12; Max/Min: 67.08333333333333\n",
      "[357, 55, 149, 72, 355, 704, 202, 38, 570]\n",
      "Round: 13; Max/Min: 62.23076923076923\n",
      "[357, 55, 149, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 14; Max/Min: 58.07142857142857\n",
      "[357, 55, 3, 149, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 15; Max/Min: 54.666666666666664\n",
      "[357, 55, 149, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 16; Max/Min: 51.5\n",
      "[357, 55, 149, 72, 355, 704, 202, 38, 570]\n",
      "Round: 17; Max/Min: 48.705882352941174\n",
      "[357, 55, 3, 149, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 18; Max/Min: 46.388888888888886\n",
      "[357, 55, 149, 72, 355, 704, 202, 38, 570]\n",
      "Round: 19; Max/Min: 44.1578947368421\n",
      "[357, 55, 149, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 20; Max/Min: 42.15\n",
      "[357, 55, 3, 149, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 21; Max/Min: 40.476190476190474\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 22; Max/Min: 38.86363636363637\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 23; Max/Min: 37.391304347826086\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 24; Max/Min: 36.166666666666664\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 25; Max/Min: 34.92\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 26; Max/Min: 33.76923076923077\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 27; Max/Min: 32.81481481481482\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 28; Max/Min: 31.821428571428573\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 29; Max/Min: 30.896551724137932\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 30; Max/Min: 30.133333333333333\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 31; Max/Min: 29.322580645161292\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 32; Max/Min: 28.5625\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 33; Max/Min: 27.939393939393938\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 34; Max/Min: 27.264705882352942\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 35; Max/Min: 26.62857142857143\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 36; Max/Min: 26.11111111111111\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 37; Max/Min: 25.54054054054054\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 38; Max/Min: 25.0\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 39; Max/Min: 24.564102564102566\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 40; Max/Min: 24.075\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 41; Max/Min: 23.609756097560975\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 42; Max/Min: 23.238095238095237\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 43; Max/Min: 22.813953488372093\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 44; Max/Min: 22.40909090909091\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 45; Max/Min: 22.08888888888889\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 46; Max/Min: 21.717391304347824\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 47; Max/Min: 21.361702127659573\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 48; Max/Min: 21.083333333333332\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 49; Max/Min: 20.755102040816325\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 50; Max/Min: 20.44\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 51; Max/Min: 20.19607843137255\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 52; Max/Min: 19.903846153846153\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 53; Max/Min: 19.62264150943396\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 54; Max/Min: 19.40740740740741\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 55; Max/Min: 19.145454545454545\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 56; Max/Min: 18.892857142857142\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 57; Max/Min: 18.70175438596491\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 58; Max/Min: 18.46551724137931\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 59; Max/Min: 18.23728813559322\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 60; Max/Min: 18.066666666666666\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 61; Max/Min: 17.852459016393443\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 62; Max/Min: 17.64516129032258\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 63; Max/Min: 17.49206349206349\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 64; Max/Min: 17.296875\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 65; Max/Min: 17.107692307692307\n",
      "[357, 55, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 66; Max/Min: 16.96969696969697\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 67; Max/Min: 16.791044776119403\n",
      "[357, 55, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 68; Max/Min: 16.61764705882353\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 69; Max/Min: 16.492753623188406\n",
      "[357, 55, 1, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 70; Max/Min: 16.34285714285714\n",
      "[357, 55, 1, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 71; Max/Min: 16.197183098591548\n",
      "[357, 55, 1, 3, 149, 160, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 72; Max/Min: 16.09722222222222\n",
      "[357, 55, 1, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 73; Max/Min: 15.95890410958904\n",
      "[357, 55, 1, 149, 160, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 74; Max/Min: 15.824324324324325\n",
      "[357, 55, 1, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 75; Max/Min: 15.733333333333333\n",
      "[357, 55, 5, 1, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 76; Max/Min: 15.631578947368421\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 77; Max/Min: 15.493506493506494\n",
      "[357, 55, 5, 3, 149, 160, 5, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 78; Max/Min: 15.423076923076923\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 79; Max/Min: 15.291139240506329\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 80; Max/Min: 15.1875\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 81; Max/Min: 15.098765432098766\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 82; Max/Min: 15.0\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 83; Max/Min: 14.879518072289157\n",
      "[357, 55, 5, 3, 149, 160, 5, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 84; Max/Min: 14.821428571428571\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 85; Max/Min: 14.705882352941176\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 86; Max/Min: 14.616279069767442\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 87; Max/Min: 14.540229885057471\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 88; Max/Min: 14.454545454545455\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 89; Max/Min: 14.348314606741573\n",
      "[357, 55, 5, 3, 149, 160, 5, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 90; Max/Min: 14.3\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 91; Max/Min: 14.197802197802197\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 92; Max/Min: 14.119565217391305\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 93; Max/Min: 14.053763440860216\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 94; Max/Min: 13.97872340425532\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 95; Max/Min: 13.884210526315789\n",
      "[357, 55, 5, 3, 149, 160, 5, 809, 72, 3, 355, 809, 704, 202, 3, 38, 570]\n",
      "Round: 96; Max/Min: 13.84375\n",
      "[357, 55, 149, 160, 72, 355, 704, 202, 38, 570]\n",
      "Round: 97; Max/Min: 13.75257731958763\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n",
      "Round: 98; Max/Min: 13.683673469387756\n",
      "[357, 55, 3, 149, 160, 72, 3, 355, 704, 202, 3, 38, 570]\n",
      "Round: 99; Max/Min: 13.626262626262626\n",
      "[357, 55, 5, 149, 160, 5, 809, 72, 355, 809, 704, 202, 38, 570]\n"
     ]
    }
   ],
   "source": [
    "newraw = duplicateMinority(raw, 23403, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041, 23448)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newraw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features, labels, and confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041, 23401)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = newraw.iloc[:,2:23403]\n",
    "X = feature.as_matrix()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041, 44)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = newraw.iloc[:,23403:-1]\n",
    "Y = label.as_matrix()\n",
    "Y = (Y==1).astype('int')\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2041,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence = newraw.iloc[:,-1]\n",
    "weight = confidence.as_matrix()\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting with Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict1_ttsplit(clf, X, Y, weight=None, test_size=0.2):\n",
    "\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "    if weight == None:\n",
    "        clf.fit(Xtrain, Ytrain)\n",
    "    else:\n",
    "        clf.fit(Xtrain, Ytrain, sample_weight=weight[train_index])\n",
    "\n",
    "    Ytrainpred = clf.predict(Xtrain)\n",
    "    Ytestpred = clf.predict(Xtest)\n",
    "\n",
    "    Ytrain = (Ytrain==1).astype('int')\n",
    "    Ytest = (Ytest==1).astype('int')\n",
    "    Ytrainpred = (Ytrainpred==1).astype('int')\n",
    "    Ytestpred = (Ytestpred==1).astype('int')\n",
    "\n",
    "    accuracytrain = metrics.accuracy_score(Ytrain, Ytrainpred)\n",
    "    accuracytest = metrics.accuracy_score(Ytest, Ytestpred)\n",
    "    hammingtrain = 1 - metrics.hamming_loss(Ytrain, Ytrainpred)\n",
    "    hammingtest = 1 - metrics.hamming_loss(Ytest, Ytestpred)\n",
    "    f1train = metrics.f1_score(Ytrain, Ytrainpred, average='micro')\n",
    "    f1test = metrics.f1_score(Ytest, Ytestpred, average='micro')\n",
    "    precisiontrain = metrics.precision_score(Ytrain, Ytrainpred, average='micro')\n",
    "    precisiontest = metrics.precision_score(Ytest, Ytestpred, average='micro')\n",
    "    recalltrain = metrics.recall_score(Ytrain, Ytrainpred, average='micro')\n",
    "    recalltest = metrics.recall_score(Ytest, Ytestpred, average='micro')\n",
    "    \n",
    "#     print(metrics.classification_report(Ytest, Ytestpred))\n",
    "    print('Accuracy: \\t \\t {} \\t {}'.format(np.array(accuracytrain).mean(), np.array(accuracytest).mean()))\n",
    "    print('Hamming: \\t \\t {} \\t {}'.format(np.array(hammingtrain).mean(), np.array(hammingtest).mean()))\n",
    "    print('Precision: \\t \\t {} \\t {}'.format(np.array(precisiontrain).mean(), np.array(precisiontest).mean()))\n",
    "    print('Recall: \\t \\t {} \\t {}'.format(np.array(recalltrain).mean(), np.array(recalltest).mean()))\n",
    "    print('F1: \\t \\t \\t {} \\t {}'.format(np.array(f1train).mean(), np.array(f1test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 0.7910539215686274 \t 0.7163814180929096\n",
      "Hamming: \t \t 0.9892908868092691 \t 0.9834963325183375\n",
      "Precision: \t \t 0.966729525862069 \t 0.9386993603411514\n",
      "Recall: \t \t 0.9321989868814131 \t 0.9063304168811117\n",
      "F1: \t \t \t 0.9491503008662302 \t 0.9222309505106048\n"
     ]
    }
   ],
   "source": [
    "predict1_ttsplit(KNeighborsClassifier(n_neighbors=3), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 0.7738970588235294 \t 0.6919315403422983\n",
      "Hamming: \t \t 0.990210004456328 \t 0.9803289619915537\n",
      "Precision: \t \t 1.0 \t 0.9613855763770585\n",
      "Recall: \t \t 0.9082604723998434 \t 0.8554825669530066\n",
      "F1: \t \t \t 0.9519250495794296 \t 0.9053475935828876\n"
     ]
    }
   ],
   "source": [
    "predict1_ttsplit(KNeighborsClassifier(n_neighbors=2), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.6748166259168704\n",
      "Hamming: \t \t 1.0 \t 0.9778839742164925\n",
      "Precision: \t \t 1.0 \t 0.8930817610062893\n",
      "Recall: \t \t 1.0 \t 0.8977871443624869\n",
      "F1: \t \t \t 1.0 \t 0.8954282711508147\n"
     ]
    }
   ],
   "source": [
    "predict1_ttsplit(KNeighborsClassifier(n_neighbors=1), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.7383863080684596\n",
      "Hamming: \t \t 1.0 \t 0.9843298510780173\n",
      "Precision: \t \t 1.0 \t 0.9505723204994797\n",
      "Recall: \t \t 1.0 \t 0.9071499503475671\n",
      "F1: \t \t \t 1.0 \t 0.9283536585365854\n"
     ]
    }
   ],
   "source": [
    "predict1_ttsplit(DecisionTreeClassifier(max_depth=None), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.7530562347188264\n",
      "Hamming: \t \t 1.0 \t 0.9868859746610358\n",
      "Precision: \t \t 1.0 \t 0.9787117903930131\n",
      "Recall: \t \t 1.0 \t 0.9010050251256282\n",
      "F1: \t \t \t 1.0 \t 0.9382522239665098\n"
     ]
    }
   ],
   "source": [
    "predict1_ttsplit(RandomForestClassifier(n_estimators=100), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.6943765281173594\n",
      "Hamming: \t \t 1.0 \t 0.9832740609024228\n",
      "Precision: \t \t 1.0 \t 0.9732620320855615\n",
      "Recall: \t \t 1.0 \t 0.8648363252375924\n",
      "F1: \t \t \t 1.0 \t 0.9158512720156556\n"
     ]
    }
   ],
   "source": [
    "predict1_ttsplit(ExtraTreesClassifier(n_estimators=100), X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict1_kfold(clf, X, Y, weight=None, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, random_state=None, shuffle=True)\n",
    "    \n",
    "    accuracytrain = []\n",
    "    accuracytest = []\n",
    "    hammingtrain = []\n",
    "    hammingtest = []\n",
    "    f1train = []\n",
    "    f1test = []\n",
    "    precisiontrain = []\n",
    "    precisiontest = []\n",
    "    recalltrain = []\n",
    "    recalltest = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Xtrain = X[train_index]\n",
    "        Ytrain = Y[train_index]\n",
    "        Xtest = X[test_index]\n",
    "        Ytest = Y[test_index]\n",
    "        \n",
    "        if weight == None:\n",
    "            clf.fit(Xtrain, Ytrain)\n",
    "        else:\n",
    "            clf.fit(Xtrain, Ytrain, sample_weight=weight[train_index])\n",
    "\n",
    "        Ytrainpred = clf.predict(Xtrain)\n",
    "        Ytestpred = clf.predict(Xtest)\n",
    "        \n",
    "        Ytrain = (Ytrain==1).astype('int')\n",
    "        Ytest = (Ytest==1).astype('int')\n",
    "        Ytrainpred = (Ytrainpred==1).astype('int')\n",
    "        Ytestpred = (Ytestpred==1).astype('int')\n",
    "        \n",
    "        accuracytrain.append(metrics.accuracy_score(Ytrain, Ytrainpred))\n",
    "        accuracytest.append(metrics.accuracy_score(Ytest, Ytestpred))\n",
    "        hammingtrain.append(1 - metrics.hamming_loss(Ytrain, Ytrainpred))\n",
    "        hammingtest.append(1 - metrics.hamming_loss(Ytest, Ytestpred))\n",
    "        f1train.append(metrics.f1_score(Ytrain, Ytrainpred, average='micro'))\n",
    "        f1test.append(metrics.f1_score(Ytest, Ytestpred, average='micro'))\n",
    "        precisiontrain.append(metrics.precision_score(Ytrain, Ytrainpred, average='micro'))\n",
    "        precisiontest.append(metrics.precision_score(Ytest, Ytestpred, average='micro'))\n",
    "        recalltrain.append(metrics.recall_score(Ytrain, Ytrainpred, average='micro'))\n",
    "        recalltest.append(metrics.recall_score(Ytest, Ytestpred, average='micro'))\n",
    "        \n",
    "#         print(metrics.classification_report(Ytest, Ytestpred))\n",
    "        \n",
    "    print('Accuracy: \\t \\t {} \\t {}'.format(np.array(accuracytrain).mean(), np.array(accuracytest).mean()))\n",
    "    print('Hamming: \\t \\t {} \\t {}'.format(np.array(hammingtrain).mean(), np.array(hammingtest).mean()))\n",
    "    print('Precision: \\t \\t {} \\t {}'.format(np.array(precisiontrain).mean(), np.array(precisiontest).mean()))\n",
    "    print('Recall: \\t \\t {} \\t {}'.format(np.array(recalltrain).mean(), np.array(recalltest).mean()))\n",
    "    print('F1: \\t \\t \\t {} \\t {}'.format(np.array(f1train).mean(), np.array(f1test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 0.7954444484468619 \t 0.6962462246512298\n",
      "Hamming: \t \t 0.9893462924333571 \t 0.980648177808576\n",
      "Precision: \t \t 0.9678482731510011 \t 0.9280235724278288\n",
      "Recall: \t \t 0.931729875546169 \t 0.8885117761339328\n",
      "F1: \t \t \t 0.9494426215240683 \t 0.9078235292482091\n"
     ]
    }
   ],
   "source": [
    "predict1_kfold(KNeighborsClassifier(n_neighbors=3), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 0.7733946303567354 \t 0.6859353276763027\n",
      "Hamming: \t \t 0.9897638002899205 \t 0.9818155940971632\n",
      "Precision: \t \t 1.0 \t 0.9644495099042096\n",
      "Recall: \t \t 0.9046483837208413 \t 0.8619719571541061\n",
      "F1: \t \t \t 0.949934531567304 \t 0.9103229386807031\n"
     ]
    }
   ],
   "source": [
    "predict1_kfold(KNeighborsClassifier(n_neighbors=2), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.7025744283043289\n",
      "Hamming: \t \t 1.0 \t 0.9785510886950913\n",
      "Precision: \t \t 1.0 \t 0.8973141492711288\n",
      "Recall: \t \t 1.0 \t 0.9036384657302259\n",
      "F1: \t \t \t 1.0 \t 0.9004412907489081\n"
     ]
    }
   ],
   "source": [
    "predict1_kfold(KNeighborsClassifier(n_neighbors=1), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.7192518816817681\n",
      "Hamming: \t \t 1.0 \t 0.9812029579557985\n",
      "Precision: \t \t 1.0 \t 0.9243444734366367\n",
      "Recall: \t \t 1.0 \t 0.8984048956162571\n",
      "F1: \t \t \t 1.0 \t 0.9111643735350118\n"
     ]
    }
   ],
   "source": [
    "predict1_kfold(DecisionTreeClassifier(max_depth=None), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 0.9998775260257196 \t 0.7319933841507263\n",
      "Hamming: \t \t 0.9999972165005845 \t 0.985714063909627\n",
      "Precision: \t \t 1.0 \t 0.9749817730411781\n",
      "Recall: \t \t 0.9999740259740261 \t 0.8899287088721175\n",
      "F1: \t \t \t 0.9999870121436457 \t 0.9304917957933109\n"
     ]
    }
   ],
   "source": [
    "predict1_kfold(RandomForestClassifier(n_estimators=100), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t \t 1.0 \t 0.7339709477923199\n",
      "Hamming: \t \t 1.0 \t 0.985235934782893\n",
      "Precision: \t \t 1.0 \t 0.9741713792194776\n",
      "Recall: \t \t 1.0 \t 0.8857374115951014\n",
      "F1: \t \t \t 1.0 \t 0.9277655181499359\n"
     ]
    }
   ],
   "source": [
    "predict1_kfold(ExtraTreesClassifier(n_estimators=100), X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
