{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<151627x1676 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1901453 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = load_npz('features_silico_duplicated.npz')\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151627, 71)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain = np.load('classes_silico_duplicated.npy')\n",
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<842x1676 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14100 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = load_npz('features_inga_dropped.npz')\n",
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 71)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest = np.load('classes_inga.npy')\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, Xtrain, Xtest, Ytrain, Ytest, threshold=0.5):\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    Ytrainprob = clf.predict_proba(Xtrain)\n",
    "    Ytrainpred = np.array(list(map(lambda x: (x[:,0]<(1-threshold)).astype('int'), Ytrainprob))).T\n",
    "    Ytestprob = clf.predict_proba(Xtest)\n",
    "    Ytestpred = np.array(list(map(lambda x: (x[:,0]<(1-threshold)).astype('int'), Ytestprob))).T\n",
    "    \n",
    "    print(metrics.classification_report(Ytrain, Ytrainpred))\n",
    "    print(metrics.classification_report(Ytest, Ytestpred))\n",
    "    \n",
    "    print('Accuracy: \\t \\t {} \\t {}'.format(metrics.accuracy_score(Ytrain, Ytrainpred), \n",
    "                                        metrics.accuracy_score(Ytest, Ytestpred)))\n",
    "    print('Hamming: \\t \\t {} \\t {}'.format(1 - metrics.hamming_loss(Ytrain, Ytrainpred), \n",
    "                                           1 - metrics.hamming_loss(Ytest, Ytestpred)))\n",
    "    print('Precision: \\t \\t {} \\t {}'.format(metrics.f1_score(Ytrain, Ytrainpred, average='micro'), \n",
    "                                             metrics.f1_score(Ytest, Ytestpred, average='micro')))\n",
    "    print('Recall: \\t \\t {} \\t {}'.format(metrics.precision_score(Ytrain, Ytrainpred, average='micro'), \n",
    "                                          metrics.precision_score(Ytest, Ytestpred, average='micro')))\n",
    "    print('F1: \\t \\t \\t {} \\t {}'.format(metrics.recall_score(Ytrain, Ytrainpred, average='micro'), \n",
    "                                         metrics.recall_score(Ytest, Ytestpred, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     78288\n",
      "          1       1.00      1.00      1.00     27660\n",
      "          2       1.00      1.00      1.00      6415\n",
      "          3       1.00      1.00      1.00     13673\n",
      "          4       1.00      1.00      1.00      2993\n",
      "          5       1.00      1.00      1.00      7849\n",
      "          6       1.00      1.00      1.00      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       1.00      1.00      1.00      3904\n",
      "          9       1.00      1.00      1.00      4168\n",
      "         10       1.00      1.00      1.00      2664\n",
      "         11       1.00      1.00      1.00      3854\n",
      "         12       1.00      1.00      1.00      3017\n",
      "         13       1.00      1.00      1.00      6571\n",
      "         14       1.00      1.00      1.00      4344\n",
      "         15       1.00      1.00      1.00     35407\n",
      "         16       1.00      1.00      1.00      3333\n",
      "         17       1.00      1.00      1.00      4096\n",
      "         18       1.00      1.00      1.00      3392\n",
      "         19       1.00      1.00      1.00      4480\n",
      "         20       1.00      1.00      1.00      3260\n",
      "         21       1.00      1.00      1.00      3776\n",
      "         22       1.00      1.00      1.00      2285\n",
      "         23       1.00      1.00      1.00      2720\n",
      "         24       1.00      1.00      1.00      4018\n",
      "         25       1.00      1.00      1.00      4805\n",
      "         26       1.00      0.99      1.00      2300\n",
      "         27       1.00      1.00      1.00      2528\n",
      "         28       1.00      1.00      1.00      3333\n",
      "         29       1.00      1.00      1.00      3212\n",
      "         30       1.00      1.00      1.00      3276\n",
      "         31       1.00      1.00      1.00      2896\n",
      "         32       1.00      1.00      1.00      3728\n",
      "         33       1.00      1.00      1.00      2841\n",
      "         34       1.00      1.00      1.00      5594\n",
      "         35       1.00      1.00      1.00     14367\n",
      "         36       1.00      1.00      1.00      2588\n",
      "         37       1.00      1.00      1.00      4714\n",
      "         38       1.00      1.00      1.00      3256\n",
      "         39       1.00      0.99      0.99      3274\n",
      "         40       1.00      1.00      1.00      2560\n",
      "         41       1.00      1.00      1.00      2432\n",
      "         42       1.00      1.00      1.00     14869\n",
      "         43       1.00      1.00      1.00      4366\n",
      "         44       0.99      1.00      1.00      7706\n",
      "         45       1.00      1.00      1.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       1.00      1.00      1.00      3103\n",
      "         48       1.00      1.00      1.00      3072\n",
      "         49       1.00      1.00      1.00      6704\n",
      "         50       1.00      1.00      1.00      2544\n",
      "         51       1.00      1.00      1.00     56630\n",
      "         52       1.00      1.00      1.00      5449\n",
      "         53       1.00      1.00      1.00      3217\n",
      "         54       1.00      1.00      1.00      6439\n",
      "         55       1.00      1.00      1.00      2992\n",
      "         56       1.00      1.00      1.00      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00      2576\n",
      "         59       1.00      1.00      1.00      9926\n",
      "         60       1.00      0.99      1.00      8331\n",
      "         61       1.00      1.00      1.00      3462\n",
      "         62       1.00      1.00      1.00      3296\n",
      "         63       1.00      1.00      1.00      2284\n",
      "         64       1.00      1.00      1.00      4228\n",
      "         65       1.00      1.00      1.00      2560\n",
      "         66       1.00      1.00      1.00      3380\n",
      "         67       1.00      1.00      1.00      3280\n",
      "         68       1.00      1.00      1.00      4192\n",
      "         69       1.00      1.00      1.00      3846\n",
      "         70       1.00      1.00      1.00      2892\n",
      "\n",
      "avg / total       1.00      1.00      1.00    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97       753\n",
      "          1       0.96      0.41      0.58       588\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.00      0.00      0.00       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       1.00      0.01      0.01       350\n",
      "          6       0.00      0.00      0.00        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       1.00      0.03      0.05       107\n",
      "         13       0.75      0.20      0.32        15\n",
      "         14       0.91      0.27      0.41       327\n",
      "         15       0.16      0.20      0.18        15\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.00      0.00      0.00         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.20      1.00      0.33         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       1.00      0.50      0.67         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.50      0.02      0.03        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.00      0.00      0.00        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.81      0.12      0.22       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.00      0.00      0.00        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.00      0.00      0.00       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.00      0.00      0.00        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       0.00      0.00      0.00       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.61      0.28      0.33      3988\n",
      "\n",
      "Accuracy: \t \t 0.9985160954183622 \t 0.021377672209026127\n",
      "Hamming: \t \t 0.9999504900693575 \t 0.9505871332508112\n",
      "Precision: \t \t 0.9994507334717665 \t 0.4303895102198227\n",
      "Recall: \t \t 0.9995382871276924 \t 0.9315525876460768\n",
      "F1: \t \t \t 0.9993631951528641 \t 0.279839518555667\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=100), Xtrain, Xtest, Ytrain, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     78288\n",
      "          1       1.00      1.00      1.00     27660\n",
      "          2       1.00      1.00      1.00      6415\n",
      "          3       1.00      1.00      1.00     13673\n",
      "          4       1.00      1.00      1.00      2993\n",
      "          5       1.00      1.00      1.00      7849\n",
      "          6       1.00      1.00      1.00      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       1.00      1.00      1.00      3904\n",
      "          9       1.00      1.00      1.00      4168\n",
      "         10       1.00      1.00      1.00      2664\n",
      "         11       1.00      1.00      1.00      3854\n",
      "         12       1.00      1.00      1.00      3017\n",
      "         13       1.00      1.00      1.00      6571\n",
      "         14       1.00      1.00      1.00      4344\n",
      "         15       1.00      1.00      1.00     35407\n",
      "         16       1.00      1.00      1.00      3333\n",
      "         17       1.00      1.00      1.00      4096\n",
      "         18       1.00      1.00      1.00      3392\n",
      "         19       1.00      1.00      1.00      4480\n",
      "         20       1.00      1.00      1.00      3260\n",
      "         21       1.00      1.00      1.00      3776\n",
      "         22       1.00      1.00      1.00      2285\n",
      "         23       1.00      1.00      1.00      2720\n",
      "         24       1.00      1.00      1.00      4018\n",
      "         25       1.00      1.00      1.00      4805\n",
      "         26       1.00      0.99      1.00      2300\n",
      "         27       1.00      1.00      1.00      2528\n",
      "         28       1.00      1.00      1.00      3333\n",
      "         29       1.00      1.00      1.00      3212\n",
      "         30       1.00      1.00      1.00      3276\n",
      "         31       1.00      1.00      1.00      2896\n",
      "         32       1.00      1.00      1.00      3728\n",
      "         33       1.00      1.00      1.00      2841\n",
      "         34       1.00      1.00      1.00      5594\n",
      "         35       1.00      1.00      1.00     14367\n",
      "         36       1.00      1.00      1.00      2588\n",
      "         37       1.00      1.00      1.00      4714\n",
      "         38       1.00      1.00      1.00      3256\n",
      "         39       0.99      0.99      0.99      3274\n",
      "         40       1.00      1.00      1.00      2560\n",
      "         41       1.00      1.00      1.00      2432\n",
      "         42       1.00      1.00      1.00     14869\n",
      "         43       1.00      1.00      1.00      4366\n",
      "         44       0.99      1.00      1.00      7706\n",
      "         45       1.00      1.00      1.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       1.00      1.00      1.00      3103\n",
      "         48       1.00      1.00      1.00      3072\n",
      "         49       1.00      1.00      1.00      6704\n",
      "         50       1.00      1.00      1.00      2544\n",
      "         51       1.00      1.00      1.00     56630\n",
      "         52       1.00      1.00      1.00      5449\n",
      "         53       1.00      1.00      1.00      3217\n",
      "         54       1.00      1.00      1.00      6439\n",
      "         55       1.00      1.00      1.00      2992\n",
      "         56       1.00      1.00      1.00      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00      2576\n",
      "         59       1.00      1.00      1.00      9926\n",
      "         60       0.99      1.00      1.00      8331\n",
      "         61       1.00      1.00      1.00      3462\n",
      "         62       1.00      1.00      1.00      3296\n",
      "         63       1.00      1.00      1.00      2284\n",
      "         64       1.00      1.00      1.00      4228\n",
      "         65       1.00      1.00      1.00      2560\n",
      "         66       1.00      1.00      1.00      3380\n",
      "         67       1.00      1.00      1.00      3280\n",
      "         68       1.00      1.00      1.00      4192\n",
      "         69       1.00      1.00      1.00      3846\n",
      "         70       1.00      1.00      1.00      2892\n",
      "\n",
      "avg / total       1.00      1.00      1.00    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97       753\n",
      "          1       0.95      0.64      0.76       588\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.78      0.03      0.07       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.88      0.10      0.18       350\n",
      "          6       0.00      0.00      0.00        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.57      0.04      0.07       107\n",
      "         13       0.75      0.20      0.32        15\n",
      "         14       0.94      0.53      0.67       327\n",
      "         15       0.09      0.20      0.12        15\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.00      0.00      0.00         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.11      1.00      0.20         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.50      0.50      0.50         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.50      0.02      0.03        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.00      0.00      0.00        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.70      0.26      0.38       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.13      0.13      0.13        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       1.00      0.00      0.01       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.00      0.00      0.00        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       0.00      0.00      0.00       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.67      0.36      0.41      3988\n",
      "\n",
      "Accuracy: \t \t 0.9980016751633943 \t 0.030878859857482184\n",
      "Hamming: \t \t 0.9999434304920052 \t 0.9543006256063699\n",
      "Precision: \t \t 0.9993725627566027 \t 0.5145700071073205\n",
      "Recall: \t \t 0.9992232889694672 \t 0.8829268292682927\n",
      "F1: \t \t \t 0.9995218811503704 \t 0.3630892678034102\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=100), Xtrain, Xtest, Ytrain, Ytest, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     78288\n",
      "          1       1.00      1.00      1.00     27660\n",
      "          2       1.00      1.00      1.00      6415\n",
      "          3       1.00      1.00      1.00     13673\n",
      "          4       1.00      1.00      1.00      2993\n",
      "          5       1.00      1.00      1.00      7849\n",
      "          6       1.00      1.00      1.00      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       1.00      1.00      1.00      3904\n",
      "          9       1.00      1.00      1.00      4168\n",
      "         10       1.00      1.00      1.00      2664\n",
      "         11       1.00      1.00      1.00      3854\n",
      "         12       1.00      1.00      1.00      3017\n",
      "         13       1.00      1.00      1.00      6571\n",
      "         14       1.00      1.00      1.00      4344\n",
      "         15       1.00      1.00      1.00     35407\n",
      "         16       0.99      1.00      1.00      3333\n",
      "         17       1.00      1.00      1.00      4096\n",
      "         18       1.00      1.00      1.00      3392\n",
      "         19       1.00      1.00      1.00      4480\n",
      "         20       1.00      1.00      1.00      3260\n",
      "         21       1.00      1.00      1.00      3776\n",
      "         22       1.00      1.00      1.00      2285\n",
      "         23       1.00      1.00      1.00      2720\n",
      "         24       0.99      1.00      0.99      4018\n",
      "         25       0.99      1.00      1.00      4805\n",
      "         26       0.99      1.00      0.99      2300\n",
      "         27       1.00      1.00      1.00      2528\n",
      "         28       0.99      1.00      1.00      3333\n",
      "         29       1.00      1.00      1.00      3212\n",
      "         30       1.00      1.00      1.00      3276\n",
      "         31       1.00      1.00      1.00      2896\n",
      "         32       1.00      1.00      1.00      3728\n",
      "         33       1.00      1.00      1.00      2841\n",
      "         34       0.99      1.00      1.00      5594\n",
      "         35       0.99      1.00      1.00     14367\n",
      "         36       1.00      1.00      1.00      2588\n",
      "         37       1.00      1.00      1.00      4714\n",
      "         38       1.00      1.00      1.00      3256\n",
      "         39       0.98      0.99      0.99      3274\n",
      "         40       1.00      1.00      1.00      2560\n",
      "         41       1.00      1.00      1.00      2432\n",
      "         42       0.99      1.00      1.00     14869\n",
      "         43       1.00      1.00      1.00      4366\n",
      "         44       0.98      1.00      0.99      7706\n",
      "         45       1.00      1.00      1.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       1.00      1.00      1.00      3103\n",
      "         48       1.00      1.00      1.00      3072\n",
      "         49       1.00      1.00      1.00      6704\n",
      "         50       1.00      1.00      1.00      2544\n",
      "         51       1.00      1.00      1.00     56630\n",
      "         52       1.00      1.00      1.00      5449\n",
      "         53       1.00      1.00      1.00      3217\n",
      "         54       1.00      1.00      1.00      6439\n",
      "         55       1.00      1.00      1.00      2992\n",
      "         56       1.00      1.00      1.00      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00      2576\n",
      "         59       0.99      1.00      0.99      9926\n",
      "         60       0.99      1.00      0.99      8331\n",
      "         61       1.00      1.00      1.00      3462\n",
      "         62       1.00      1.00      1.00      3296\n",
      "         63       1.00      1.00      1.00      2284\n",
      "         64       1.00      1.00      1.00      4228\n",
      "         65       1.00      1.00      1.00      2560\n",
      "         66       1.00      1.00      1.00      3380\n",
      "         67       1.00      1.00      1.00      3280\n",
      "         68       1.00      1.00      1.00      4192\n",
      "         69       1.00      1.00      1.00      3846\n",
      "         70       1.00      1.00      1.00      2892\n",
      "\n",
      "avg / total       1.00      1.00      1.00    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97       753\n",
      "          1       0.94      0.82      0.88       588\n",
      "          2       0.64      0.18      0.28        39\n",
      "          3       0.51      0.12      0.19       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.88      0.29      0.43       350\n",
      "          6       0.00      0.00      0.00        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.45      0.05      0.08       107\n",
      "         13       0.60      0.40      0.48        15\n",
      "         14       0.89      0.71      0.79       327\n",
      "         15       0.08      0.27      0.12        15\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.00      0.00      0.00         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.03      1.00      0.07         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.25      0.50      0.33         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.80      0.12      0.22        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       1.00      0.02      0.04        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.51      0.52      0.52       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.07      0.13      0.10        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.75      0.02      0.05       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.50      0.02      0.04        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       0.78      0.06      0.11       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.67      0.46      0.50      3988\n",
      "\n",
      "Accuracy: \t \t 0.9937280299682775 \t 0.05819477434679335\n",
      "Hamming: \t \t 0.9998645675818448 \t 0.9558897326954602\n",
      "Precision: \t \t 0.9984995646885207 \t 0.5834781235191913\n",
      "Recall: \t \t 0.9972188134014961 \t 0.7883055911224925\n",
      "F1: \t \t \t 0.9997836100034004 \t 0.4631394182547643\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=100), Xtrain, Xtest, Ytrain, Ytest, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     78288\n",
      "          1       0.99      1.00      1.00     27660\n",
      "          2       0.99      1.00      1.00      6415\n",
      "          3       1.00      1.00      1.00     13673\n",
      "          4       1.00      1.00      1.00      2993\n",
      "          5       1.00      1.00      1.00      7849\n",
      "          6       1.00      1.00      1.00      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       1.00      1.00      1.00      3904\n",
      "          9       1.00      1.00      1.00      4168\n",
      "         10       0.99      1.00      0.99      2664\n",
      "         11       1.00      1.00      1.00      3854\n",
      "         12       1.00      1.00      1.00      3017\n",
      "         13       1.00      1.00      1.00      6571\n",
      "         14       1.00      1.00      1.00      4344\n",
      "         15       0.99      1.00      1.00     35407\n",
      "         16       0.99      1.00      0.99      3333\n",
      "         17       1.00      1.00      1.00      4096\n",
      "         18       1.00      1.00      1.00      3392\n",
      "         19       1.00      1.00      1.00      4480\n",
      "         20       1.00      1.00      1.00      3260\n",
      "         21       1.00      1.00      1.00      3776\n",
      "         22       1.00      1.00      1.00      2285\n",
      "         23       1.00      1.00      1.00      2720\n",
      "         24       0.99      1.00      0.99      4018\n",
      "         25       0.99      1.00      0.99      4805\n",
      "         26       0.98      1.00      0.99      2300\n",
      "         27       1.00      1.00      1.00      2528\n",
      "         28       0.99      1.00      0.99      3333\n",
      "         29       1.00      1.00      1.00      3212\n",
      "         30       1.00      1.00      1.00      3276\n",
      "         31       1.00      1.00      1.00      2896\n",
      "         32       1.00      1.00      1.00      3728\n",
      "         33       1.00      1.00      1.00      2841\n",
      "         34       0.99      1.00      0.99      5594\n",
      "         35       0.98      1.00      0.99     14367\n",
      "         36       0.98      1.00      0.99      2588\n",
      "         37       1.00      1.00      1.00      4714\n",
      "         38       0.99      1.00      1.00      3256\n",
      "         39       0.96      1.00      0.98      3274\n",
      "         40       1.00      1.00      1.00      2560\n",
      "         41       0.99      1.00      1.00      2432\n",
      "         42       0.98      1.00      0.99     14869\n",
      "         43       0.99      1.00      0.99      4366\n",
      "         44       0.96      1.00      0.98      7706\n",
      "         45       1.00      1.00      1.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       1.00      1.00      1.00      3103\n",
      "         48       1.00      1.00      1.00      3072\n",
      "         49       1.00      1.00      1.00      6704\n",
      "         50       1.00      1.00      1.00      2544\n",
      "         51       0.99      1.00      0.99     56630\n",
      "         52       1.00      1.00      1.00      5449\n",
      "         53       0.99      1.00      1.00      3217\n",
      "         54       1.00      1.00      1.00      6439\n",
      "         55       1.00      1.00      1.00      2992\n",
      "         56       1.00      1.00      1.00      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00      2576\n",
      "         59       0.97      1.00      0.99      9926\n",
      "         60       0.97      1.00      0.98      8331\n",
      "         61       1.00      1.00      1.00      3462\n",
      "         62       1.00      1.00      1.00      3296\n",
      "         63       0.99      1.00      0.99      2284\n",
      "         64       1.00      1.00      1.00      4228\n",
      "         65       1.00      1.00      1.00      2560\n",
      "         66       1.00      1.00      1.00      3380\n",
      "         67       1.00      1.00      1.00      3280\n",
      "         68       1.00      1.00      1.00      4192\n",
      "         69       1.00      1.00      1.00      3846\n",
      "         70       0.99      1.00      0.99      2892\n",
      "\n",
      "avg / total       0.99      1.00      1.00    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       753\n",
      "          1       0.90      0.89      0.90       588\n",
      "          2       0.20      0.38      0.27        39\n",
      "          3       0.46      0.31      0.37       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.84      0.69      0.76       350\n",
      "          6       1.00      0.01      0.03        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.50      0.11      0.18         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.59      0.15      0.24       107\n",
      "         13       0.50      0.73      0.59        15\n",
      "         14       0.78      0.83      0.80       327\n",
      "         15       0.06      0.33      0.10        15\n",
      "         16       1.00      0.11      0.20         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.12      1.00      0.22         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       1.00      0.11      0.20         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      0.11      0.20         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.02      1.00      0.03         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.11      0.50      0.18         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.88      0.22      0.35        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.75      0.06      0.11        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.50      0.80      0.62       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.80      0.40      0.53        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.04      0.13      0.06        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.05      0.50      0.09         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.80      0.18      0.30       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.25      0.02      0.04        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       0.72      0.41      0.52       124\n",
      "         69       0.50      0.08      0.14        36\n",
      "         70       0.29      0.09      0.13        23\n",
      "\n",
      "avg / total       0.67      0.59      0.58      3988\n",
      "\n",
      "Accuracy: \t \t 0.9781503294268171 \t 0.052256532066508314\n",
      "Hamming: \t \t 0.9996003907661843 \t 0.9545348098089727\n",
      "Precision: \t \t 0.9955860806612465 \t 0.6340872374798062\n",
      "Recall: \t \t 0.9913405760825812 \t 0.684593023255814\n",
      "F1: \t \t \t 0.9998681051449297 \t 0.5905215646940822\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=100), Xtrain, Xtest, Ytrain, Ytest, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98     78288\n",
      "          1       0.97      1.00      0.99     27660\n",
      "          2       0.95      1.00      0.97      6415\n",
      "          3       0.97      1.00      0.98     13673\n",
      "          4       0.97      1.00      0.99      2993\n",
      "          5       1.00      1.00      1.00      7849\n",
      "          6       1.00      1.00      1.00      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       1.00      1.00      1.00      3904\n",
      "          9       1.00      1.00      1.00      4168\n",
      "         10       0.97      1.00      0.98      2664\n",
      "         11       0.99      1.00      0.99      3854\n",
      "         12       0.98      1.00      0.99      3017\n",
      "         13       0.99      1.00      1.00      6571\n",
      "         14       0.99      1.00      1.00      4344\n",
      "         15       0.98      1.00      0.99     35407\n",
      "         16       0.97      1.00      0.98      3333\n",
      "         17       1.00      1.00      1.00      4096\n",
      "         18       1.00      1.00      1.00      3392\n",
      "         19       1.00      1.00      1.00      4480\n",
      "         20       0.99      1.00      1.00      3260\n",
      "         21       1.00      1.00      1.00      3776\n",
      "         22       0.99      1.00      1.00      2285\n",
      "         23       1.00      1.00      1.00      2720\n",
      "         24       0.96      1.00      0.98      4018\n",
      "         25       0.97      1.00      0.98      4805\n",
      "         26       0.95      1.00      0.97      2300\n",
      "         27       1.00      1.00      1.00      2528\n",
      "         28       0.97      1.00      0.98      3333\n",
      "         29       0.99      1.00      1.00      3212\n",
      "         30       0.98      1.00      0.99      3276\n",
      "         31       0.99      1.00      1.00      2896\n",
      "         32       0.99      1.00      1.00      3728\n",
      "         33       0.99      1.00      0.99      2841\n",
      "         34       0.96      1.00      0.98      5594\n",
      "         35       0.95      1.00      0.97     14367\n",
      "         36       0.95      1.00      0.97      2588\n",
      "         37       0.98      1.00      0.99      4714\n",
      "         38       0.98      1.00      0.99      3256\n",
      "         39       0.88      1.00      0.93      3274\n",
      "         40       1.00      1.00      1.00      2560\n",
      "         41       0.99      1.00      0.99      2432\n",
      "         42       0.93      1.00      0.96     14869\n",
      "         43       0.96      1.00      0.98      4366\n",
      "         44       0.89      1.00      0.94      7706\n",
      "         45       1.00      1.00      1.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.99      1.00      1.00      3103\n",
      "         48       1.00      1.00      1.00      3072\n",
      "         49       0.98      1.00      0.99      6704\n",
      "         50       1.00      1.00      1.00      2544\n",
      "         51       0.96      1.00      0.98     56630\n",
      "         52       0.95      1.00      0.98      5449\n",
      "         53       0.95      1.00      0.98      3217\n",
      "         54       0.98      1.00      0.99      6439\n",
      "         55       0.99      1.00      0.99      2992\n",
      "         56       0.99      1.00      0.99      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00      2576\n",
      "         59       0.92      1.00      0.96      9926\n",
      "         60       0.89      1.00      0.94      8331\n",
      "         61       0.97      1.00      0.98      3462\n",
      "         62       1.00      1.00      1.00      3296\n",
      "         63       0.95      1.00      0.97      2284\n",
      "         64       0.99      1.00      1.00      4228\n",
      "         65       1.00      1.00      1.00      2560\n",
      "         66       0.98      1.00      0.99      3380\n",
      "         67       1.00      1.00      1.00      3280\n",
      "         68       1.00      1.00      1.00      4192\n",
      "         69       0.97      1.00      0.98      3846\n",
      "         70       0.93      1.00      0.96      2892\n",
      "\n",
      "avg / total       0.97      1.00      0.98    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.94       753\n",
      "          1       0.83      0.96      0.89       588\n",
      "          2       0.09      0.77      0.16        39\n",
      "          3       0.34      0.71      0.46       202\n",
      "          4       0.09      0.20      0.13        15\n",
      "          5       0.70      0.90      0.79       350\n",
      "          6       0.53      0.26      0.35        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.07      0.22      0.11         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.46      0.25      0.33       107\n",
      "         13       0.34      0.73      0.47        15\n",
      "         14       0.58      0.94      0.72       327\n",
      "         15       0.07      0.87      0.12        15\n",
      "         16       0.40      0.22      0.29         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.04      1.00      0.08         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.40      0.22      0.29         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.11      1.00      0.20         1\n",
      "         33       0.40      0.22      0.29         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.01      1.00      0.01         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.03      0.50      0.05         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.83      0.59      0.69        64\n",
      "         43       1.00      0.14      0.24        29\n",
      "         44       0.65      0.28      0.39        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.04      0.01      0.02        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.48      0.95      0.64       401\n",
      "         52       0.11      0.01      0.03        67\n",
      "         53       0.67      0.40      0.50        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.71      0.31      0.43        16\n",
      "         56       0.71      0.71      0.71         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       0.07      0.67      0.12        15\n",
      "         60       0.09      0.36      0.14        11\n",
      "         61       0.02      1.00      0.03         2\n",
      "         62       0.11      0.04      0.06        23\n",
      "         63       0.10      0.17      0.12        12\n",
      "         64       0.57      0.65      0.61       242\n",
      "         65       0.80      0.07      0.14        54\n",
      "         66       0.16      0.30      0.21        43\n",
      "         67       1.00      0.02      0.04        45\n",
      "         68       0.34      0.75      0.47       124\n",
      "         69       0.25      0.44      0.32        36\n",
      "         70       0.18      0.74      0.29        23\n",
      "\n",
      "avg / total       0.61      0.75      0.63      3988\n",
      "\n",
      "Accuracy: \t \t 0.9248814525117558 \t 0.021377672209026127\n",
      "Hamming: \t \t 0.9985267776735665 \t 0.930631293700445\n",
      "Precision: \t \t 0.9839200259550654 \t 0.5890397383807353\n",
      "Recall: \t \t 0.9683586617041021 \t 0.486973619531378\n",
      "F1: \t \t \t 0.9999896957144476 \t 0.7452357071213641\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=100), Xtrain, Xtest, Ytrain, Ytest, threshold=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
