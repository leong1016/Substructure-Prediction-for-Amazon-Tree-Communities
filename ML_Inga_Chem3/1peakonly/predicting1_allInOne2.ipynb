{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<151627x1676 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1901453 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = load_npz('features_silico_duplicated.npz')\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151627, 71)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain = np.load('classes_silico_duplicated.npy')\n",
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<842x1676 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14100 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = load_npz('features_inga_dropped.npz')\n",
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 71)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest = np.load('classes_inga.npy')\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, Xtrain, Xtest, Ytrain, Ytest, threshold=0.5):\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    Ytrainprob = clf.predict_proba(Xtrain)\n",
    "    Ytrainpred = np.array(list(map(lambda x: (x[:,0]<(1-threshold)).astype('int'), Ytrainprob))).T\n",
    "    Ytestprob = clf.predict_proba(Xtest)\n",
    "    Ytestpred = np.array(list(map(lambda x: (x[:,0]<(1-threshold)).astype('int'), Ytestprob))).T\n",
    "    \n",
    "    print(metrics.classification_report(Ytrain, Ytrainpred))\n",
    "    print(metrics.classification_report(Ytest, Ytestpred))\n",
    "    \n",
    "    print('Accuracy: \\t \\t {} \\t {}'.format(metrics.accuracy_score(Ytrain, Ytrainpred), \n",
    "                                        metrics.accuracy_score(Ytest, Ytestpred)))\n",
    "    print('Hamming: \\t \\t {} \\t {}'.format(1 - metrics.hamming_loss(Ytrain, Ytrainpred), \n",
    "                                           1 - metrics.hamming_loss(Ytest, Ytestpred)))\n",
    "    print('Precision: \\t \\t {} \\t {}'.format(metrics.f1_score(Ytrain, Ytrainpred, average='micro'), \n",
    "                                             metrics.f1_score(Ytest, Ytestpred, average='micro')))\n",
    "    print('Recall: \\t \\t {} \\t {}'.format(metrics.precision_score(Ytrain, Ytrainpred, average='micro'), \n",
    "                                          metrics.precision_score(Ytest, Ytestpred, average='micro')))\n",
    "    print('F1: \\t \\t \\t {} \\t {}'.format(metrics.recall_score(Ytrain, Ytrainpred, average='micro'), \n",
    "                                         metrics.recall_score(Ytest, Ytestpred, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.69      0.80     78288\n",
      "          1       0.97      0.53      0.68     27660\n",
      "          2       0.00      0.00      0.00      6415\n",
      "          3       0.99      0.42      0.59     13673\n",
      "          4       0.00      0.00      0.00      2993\n",
      "          5       1.00      0.24      0.38      7849\n",
      "          6       1.00      0.33      0.50      3550\n",
      "          7       1.00      0.75      0.86      4096\n",
      "          8       1.00      0.52      0.69      3904\n",
      "          9       1.00      0.49      0.66      4168\n",
      "         10       0.00      0.00      0.00      2664\n",
      "         11       0.00      0.00      0.00      3854\n",
      "         12       0.00      0.00      0.00      3017\n",
      "         13       1.00      0.54      0.70      6571\n",
      "         14       1.00      0.31      0.47      4344\n",
      "         15       1.00      0.49      0.66     35407\n",
      "         16       1.00      0.08      0.14      3333\n",
      "         17       1.00      0.50      0.67      4096\n",
      "         18       0.00      0.00      0.00      3392\n",
      "         19       1.00      0.13      0.23      4480\n",
      "         20       0.00      0.00      0.00      3260\n",
      "         21       0.00      0.00      0.00      3776\n",
      "         22       0.00      0.00      0.00      2285\n",
      "         23       1.00      0.15      0.26      2720\n",
      "         24       0.00      0.00      0.00      4018\n",
      "         25       0.00      0.00      0.00      4805\n",
      "         26       0.00      0.00      0.00      2300\n",
      "         27       0.00      0.00      0.00      2528\n",
      "         28       1.00      0.08      0.14      3333\n",
      "         29       0.00      0.00      0.00      3212\n",
      "         30       0.00      0.00      0.00      3276\n",
      "         31       0.00      0.00      0.00      2896\n",
      "         32       0.00      0.00      0.00      3728\n",
      "         33       1.00      0.09      0.17      2841\n",
      "         34       0.00      0.00      0.00      5594\n",
      "         35       1.00      0.14      0.25     14367\n",
      "         36       0.00      0.00      0.00      2588\n",
      "         37       1.00      0.08      0.16      4714\n",
      "         38       0.00      0.00      0.00      3256\n",
      "         39       0.00      0.00      0.00      3274\n",
      "         40       0.00      0.00      0.00      2560\n",
      "         41       0.00      0.00      0.00      2432\n",
      "         42       1.00      0.06      0.11     14869\n",
      "         43       0.00      0.00      0.00      4366\n",
      "         44       0.00      0.00      0.00      7706\n",
      "         45       0.00      0.00      0.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00      3103\n",
      "         48       0.00      0.00      0.00      3072\n",
      "         49       0.00      0.00      0.00      6704\n",
      "         50       0.00      0.00      0.00      2544\n",
      "         51       0.92      0.72      0.81     56630\n",
      "         52       1.00      0.02      0.05      5449\n",
      "         53       0.00      0.00      0.00      3217\n",
      "         54       1.00      0.48      0.65      6439\n",
      "         55       0.00      0.00      0.00      2992\n",
      "         56       0.00      0.00      0.00      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      0.10      0.18      2576\n",
      "         59       1.00      0.03      0.06      9926\n",
      "         60       0.00      0.00      0.00      8331\n",
      "         61       0.00      0.00      0.00      3462\n",
      "         62       1.00      0.04      0.08      3296\n",
      "         63       0.00      0.00      0.00      2284\n",
      "         64       1.00      0.31      0.47      4228\n",
      "         65       1.00      0.19      0.32      2560\n",
      "         66       0.99      0.17      0.29      3380\n",
      "         67       1.00      0.23      0.37      3280\n",
      "         68       1.00      0.27      0.42      4192\n",
      "         69       1.00      0.21      0.34      3846\n",
      "         70       0.00      0.00      0.00      2892\n",
      "\n",
      "avg / total       0.70      0.34      0.42    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.85      0.91       753\n",
      "          1       0.98      0.42      0.59       588\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.00      0.00      0.00       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.00      0.00      0.00       350\n",
      "          6       0.00      0.00      0.00        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.00      0.00      0.00       107\n",
      "         13       0.00      0.00      0.00        15\n",
      "         14       0.93      0.32      0.48       327\n",
      "         15       0.25      0.07      0.11        15\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.00      0.00      0.00         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      0.00      0.00         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.00      0.00      0.00        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.00      0.00      0.00        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.50      0.01      0.02       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.00      0.00      0.00        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.00      0.00      0.00       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.00      0.00      0.00        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       0.00      0.00      0.00       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.46      0.25      0.30      3988\n",
      "\n",
      "Accuracy: \t \t 0.14103688657033378 \t 0.014251781472684086\n",
      "Hamming: \t \t 0.9695002107190951 \t 0.9494329396808404\n",
      "Precision: \t \t 0.4980677628240013 \t 0.39672720015964874\n",
      "Recall: \t \t 0.9643637267727861 \t 0.9716520039100685\n",
      "F1: \t \t \t 0.33573217100992303 \t 0.24924774322968907\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=10, max_depth=10), Xtrain, Xtest, Ytrain, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.96      0.80     78288\n",
      "          1       0.93      0.64      0.76     27660\n",
      "          2       1.00      0.01      0.01      6415\n",
      "          3       0.97      0.55      0.70     13673\n",
      "          4       0.00      0.00      0.00      2993\n",
      "          5       1.00      0.34      0.51      7849\n",
      "          6       1.00      0.47      0.64      3550\n",
      "          7       1.00      0.75      0.86      4096\n",
      "          8       1.00      0.66      0.79      3904\n",
      "          9       1.00      0.61      0.76      4168\n",
      "         10       1.00      0.01      0.03      2664\n",
      "         11       0.00      0.00      0.00      3854\n",
      "         12       1.00      0.02      0.03      3017\n",
      "         13       1.00      0.60      0.75      6571\n",
      "         14       1.00      0.15      0.26      4344\n",
      "         15       0.98      0.62      0.76     35407\n",
      "         16       1.00      0.27      0.43      3333\n",
      "         17       1.00      0.50      0.67      4096\n",
      "         18       1.00      0.23      0.37      3392\n",
      "         19       1.00      0.20      0.33      4480\n",
      "         20       1.00      0.16      0.27      3260\n",
      "         21       1.00      0.30      0.46      3776\n",
      "         22       0.00      0.00      0.00      2285\n",
      "         23       1.00      0.48      0.65      2720\n",
      "         24       1.00      0.10      0.19      4018\n",
      "         25       1.00      0.09      0.16      4805\n",
      "         26       0.00      0.00      0.00      2300\n",
      "         27       1.00      0.20      0.34      2528\n",
      "         28       1.00      0.27      0.43      3333\n",
      "         29       1.00      0.13      0.23      3212\n",
      "         30       1.00      0.16      0.27      3276\n",
      "         31       1.00      0.18      0.30      2896\n",
      "         32       1.00      0.07      0.14      3728\n",
      "         33       1.00      0.32      0.49      2841\n",
      "         34       1.00      0.07      0.14      5594\n",
      "         35       1.00      0.20      0.34     14367\n",
      "         36       0.00      0.00      0.00      2588\n",
      "         37       1.00      0.28      0.44      4714\n",
      "         38       0.00      0.00      0.00      3256\n",
      "         39       0.00      0.00      0.00      3274\n",
      "         40       1.00      0.20      0.33      2560\n",
      "         41       0.00      0.00      0.00      2432\n",
      "         42       0.99      0.19      0.32     14869\n",
      "         43       0.00      0.00      0.00      4366\n",
      "         44       1.00      0.00      0.01      7706\n",
      "         45       0.00      0.00      0.00      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00      3103\n",
      "         48       0.00      0.00      0.00      3072\n",
      "         49       1.00      0.00      0.00      6704\n",
      "         50       0.00      0.00      0.00      2544\n",
      "         51       0.86      0.80      0.83     56630\n",
      "         52       1.00      0.02      0.05      5449\n",
      "         53       0.00      0.00      0.00      3217\n",
      "         54       1.00      0.49      0.66      6439\n",
      "         55       0.00      0.00      0.00      2992\n",
      "         56       0.00      0.00      0.00      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      0.35      0.52      2576\n",
      "         59       1.00      0.10      0.18      9926\n",
      "         60       0.00      0.00      0.00      8331\n",
      "         61       1.00      0.00      0.00      3462\n",
      "         62       1.00      0.31      0.47      3296\n",
      "         63       0.00      0.00      0.00      2284\n",
      "         64       0.99      0.38      0.54      4228\n",
      "         65       1.00      0.33      0.50      2560\n",
      "         66       0.99      0.18      0.31      3380\n",
      "         67       1.00      0.12      0.22      3280\n",
      "         68       1.00      0.40      0.57      4192\n",
      "         69       1.00      0.15      0.26      3846\n",
      "         70       0.92      0.00      0.01      2892\n",
      "\n",
      "avg / total       0.80      0.45      0.49    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95       753\n",
      "          1       0.95      0.40      0.57       588\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.30      0.03      0.06       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.00      0.00      0.00       350\n",
      "          6       0.00      0.00      0.00        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.00      0.00      0.00       107\n",
      "         13       0.00      0.00      0.00        15\n",
      "         14       1.00      0.00      0.01       327\n",
      "         15       0.25      0.07      0.11        15\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.00      0.00      0.00         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      0.00      0.00         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.00      0.00      0.00        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.00      0.00      0.00        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.47      0.31      0.38       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.00      0.00      0.00        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.00      0.00      0.00       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.00      0.00      0.00        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       0.00      0.00      0.00       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.46      0.28      0.31      3988\n",
      "\n",
      "Accuracy: \t \t 0.16604562511953677 \t 0.0023752969121140144\n",
      "Hamming: \t \t 0.9710687373397859 \t 0.9480278344652237\n",
      "Precision: \t \t 0.5819530868307035 \t 0.4189265008415934\n",
      "Recall: \t \t 0.8344386665178348 \t 0.8241353936718175\n",
      "F1: \t \t \t 0.44676909126505715 \t 0.28084252758274825\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=10, max_depth=10), Xtrain, Xtest, Ytrain, Ytest, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      1.00      0.71     78288\n",
      "          1       0.83      0.76      0.80     27660\n",
      "          2       0.97      0.08      0.15      6415\n",
      "          3       0.92      0.69      0.79     13673\n",
      "          4       0.99      0.06      0.12      2993\n",
      "          5       0.97      0.57      0.72      7849\n",
      "          6       1.00      0.55      0.71      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       1.00      0.72      0.84      3904\n",
      "          9       1.00      0.63      0.78      4168\n",
      "         10       0.97      0.12      0.21      2664\n",
      "         11       1.00      0.07      0.12      3854\n",
      "         12       0.99      0.09      0.16      3017\n",
      "         13       0.98      0.82      0.89      6571\n",
      "         14       0.99      0.67      0.80      4344\n",
      "         15       0.70      0.79      0.74     35407\n",
      "         16       1.00      0.41      0.58      3333\n",
      "         17       1.00      0.50      0.67      4096\n",
      "         18       1.00      0.34      0.51      3392\n",
      "         19       1.00      0.17      0.29      4480\n",
      "         20       1.00      0.31      0.48      3260\n",
      "         21       1.00      0.38      0.55      3776\n",
      "         22       0.00      0.00      0.00      2285\n",
      "         23       1.00      0.70      0.82      2720\n",
      "         24       1.00      0.17      0.29      4018\n",
      "         25       1.00      0.14      0.25      4805\n",
      "         26       0.00      0.00      0.00      2300\n",
      "         27       1.00      0.41      0.58      2528\n",
      "         28       1.00      0.41      0.58      3333\n",
      "         29       1.00      0.13      0.23      3212\n",
      "         30       1.00      0.31      0.48      3276\n",
      "         31       1.00      0.35      0.52      2896\n",
      "         32       1.00      0.01      0.02      3728\n",
      "         33       1.00      0.46      0.63      2841\n",
      "         34       1.00      0.12      0.21      5594\n",
      "         35       1.00      0.23      0.37     14367\n",
      "         36       0.00      0.00      0.00      2588\n",
      "         37       1.00      0.40      0.58      4714\n",
      "         38       0.00      0.00      0.00      3256\n",
      "         39       0.00      0.00      0.00      3274\n",
      "         40       1.00      0.40      0.57      2560\n",
      "         41       1.00      0.05      0.10      2432\n",
      "         42       0.91      0.27      0.41     14869\n",
      "         43       0.96      0.55      0.70      4366\n",
      "         44       0.98      0.34      0.51      7706\n",
      "         45       0.96      0.64      0.77      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.99      0.08      0.15      3103\n",
      "         48       0.99      0.08      0.15      3072\n",
      "         49       0.88      0.27      0.41      6704\n",
      "         50       1.00      0.01      0.02      2544\n",
      "         51       0.74      0.98      0.84     56630\n",
      "         52       0.99      0.07      0.13      5449\n",
      "         53       1.00      0.11      0.20      3217\n",
      "         54       1.00      0.50      0.66      6439\n",
      "         55       1.00      0.24      0.38      2992\n",
      "         56       1.00      0.25      0.39      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      0.51      0.67      2576\n",
      "         59       1.00      0.15      0.26      9926\n",
      "         60       0.00      0.00      0.00      8331\n",
      "         61       1.00      0.01      0.03      3462\n",
      "         62       0.98      0.40      0.57      3296\n",
      "         63       0.99      0.06      0.12      2284\n",
      "         64       0.94      0.56      0.70      4228\n",
      "         65       1.00      0.39      0.56      2560\n",
      "         66       0.99      0.28      0.44      3380\n",
      "         67       0.95      0.51      0.66      3280\n",
      "         68       0.99      0.56      0.71      4192\n",
      "         69       0.92      0.47      0.62      3846\n",
      "         70       1.00      0.01      0.02      2892\n",
      "\n",
      "avg / total       0.81      0.57      0.57    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.94       753\n",
      "          1       0.90      0.68      0.78       588\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.35      0.06      0.11       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.59      0.03      0.05       350\n",
      "          6       0.00      0.00      0.00        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.00      0.00      0.00       107\n",
      "         13       1.00      0.07      0.12        15\n",
      "         14       0.91      0.50      0.64       327\n",
      "         15       0.14      0.27      0.18        15\n",
      "         16       0.00      0.00      0.00         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.00      0.00      0.00         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.00      0.00      0.00         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      0.00      0.00         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       1.00      0.05      0.09        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.00      0.00      0.00        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.53      0.54      0.54       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.00      0.00      0.00        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.67      0.01      0.02       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.00      0.00      0.00        43\n",
      "         67       0.00      0.00      0.00        45\n",
      "         68       1.00      0.01      0.02       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.59      0.39      0.41      3988\n",
      "\n",
      "Accuracy: \t \t 0.19052015801935013 \t 0.032066508313539195\n",
      "Hamming: \t \t 0.9710779333681792 \t 0.9528453380616239\n",
      "Precision: \t \t 0.6389335027953109 \t 0.5261388468650193\n",
      "Recall: \t \t 0.7305397478666249 \t 0.7980622131565528\n",
      "F1: \t \t \t 0.567741403649778 \t 0.3924272818455366\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=10, max_depth=10), Xtrain, Xtest, Ytrain, Ytest, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      1.00      0.69     78288\n",
      "          1       0.69      0.86      0.77     27660\n",
      "          2       0.80      0.26      0.39      6415\n",
      "          3       0.73      0.80      0.76     13673\n",
      "          4       0.94      0.23      0.37      2993\n",
      "          5       0.88      0.70      0.78      7849\n",
      "          6       0.96      0.60      0.74      3550\n",
      "          7       1.00      1.00      1.00      4096\n",
      "          8       0.99      0.74      0.84      3904\n",
      "          9       0.98      0.70      0.82      4168\n",
      "         10       0.95      0.16      0.28      2664\n",
      "         11       1.00      0.00      0.01      3854\n",
      "         12       1.00      0.12      0.21      3017\n",
      "         13       0.96      0.82      0.89      6571\n",
      "         14       0.93      0.68      0.79      4344\n",
      "         15       0.47      0.98      0.63     35407\n",
      "         16       1.00      0.50      0.67      3333\n",
      "         17       0.94      0.50      0.65      4096\n",
      "         18       1.00      0.41      0.58      3392\n",
      "         19       0.96      0.41      0.58      4480\n",
      "         20       0.97      0.81      0.89      3260\n",
      "         21       0.96      0.59      0.73      3776\n",
      "         22       1.00      0.23      0.37      2285\n",
      "         23       1.00      0.73      0.84      2720\n",
      "         24       0.99      0.37      0.54      4018\n",
      "         25       0.98      0.32      0.48      4805\n",
      "         26       1.00      0.06      0.11      2300\n",
      "         27       1.00      0.41      0.58      2528\n",
      "         28       1.00      0.50      0.67      3333\n",
      "         29       0.99      0.29      0.44      3212\n",
      "         30       1.00      0.32      0.48      3276\n",
      "         31       1.00      0.36      0.53      2896\n",
      "         32       1.00      0.14      0.25      3728\n",
      "         33       1.00      0.57      0.73      2841\n",
      "         34       0.99      0.27      0.43      5594\n",
      "         35       0.96      0.35      0.52     14367\n",
      "         36       1.00      0.00      0.01      2588\n",
      "         37       1.00      0.43      0.60      4714\n",
      "         38       0.00      0.00      0.00      3256\n",
      "         39       0.00      0.00      0.00      3274\n",
      "         40       0.96      0.80      0.87      2560\n",
      "         41       1.00      0.05      0.10      2432\n",
      "         42       0.50      0.58      0.54     14869\n",
      "         43       0.98      0.45      0.62      4366\n",
      "         44       0.86      0.40      0.54      7706\n",
      "         45       0.98      0.53      0.69      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.99      0.08      0.15      3103\n",
      "         48       0.99      0.08      0.15      3072\n",
      "         49       0.99      0.29      0.45      6704\n",
      "         50       0.00      0.00      0.00      2544\n",
      "         51       0.46      1.00      0.63     56630\n",
      "         52       0.88      0.16      0.27      5449\n",
      "         53       1.00      0.06      0.11      3217\n",
      "         54       0.99      0.50      0.66      6439\n",
      "         55       1.00      0.28      0.43      2992\n",
      "         56       1.00      0.29      0.45      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      0.63      0.77      2576\n",
      "         59       0.98      0.18      0.31      9926\n",
      "         60       1.00      0.02      0.03      8331\n",
      "         61       1.00      0.01      0.03      3462\n",
      "         62       0.96      0.52      0.67      3296\n",
      "         63       0.91      0.23      0.37      2284\n",
      "         64       0.92      0.61      0.73      4228\n",
      "         65       0.96      0.60      0.74      2560\n",
      "         66       0.93      0.53      0.68      3380\n",
      "         67       0.92      0.57      0.70      3280\n",
      "         68       0.92      0.72      0.81      4192\n",
      "         69       0.83      0.62      0.71      3846\n",
      "         70       0.92      0.07      0.13      2892\n",
      "\n",
      "avg / total       0.74      0.64      0.58    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       753\n",
      "          1       0.81      0.89      0.85       588\n",
      "          2       0.00      0.00      0.00        39\n",
      "          3       0.40      0.27      0.33       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.79      0.15      0.25       350\n",
      "          6       0.73      0.16      0.26        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.00      0.00      0.00        68\n",
      "         12       0.00      0.00      0.00       107\n",
      "         13       0.64      0.47      0.54        15\n",
      "         14       0.84      0.20      0.32       327\n",
      "         15       0.04      0.80      0.07        15\n",
      "         16       1.00      0.11      0.20         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       1.00      0.11      0.20         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       1.00      1.00      1.00         1\n",
      "         33       1.00      0.11      0.20         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.33      1.00      0.50         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.00      0.00      0.00        64\n",
      "         43       0.00      0.00      0.00        29\n",
      "         44       0.00      0.00      0.00        53\n",
      "         45       0.00      0.00      0.00         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.48      1.00      0.65       401\n",
      "         52       0.00      0.00      0.00        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.00      0.00      0.00        16\n",
      "         56       0.00      0.00      0.00         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       1.00      1.00      1.00         1\n",
      "         59       0.50      0.07      0.12        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.71      0.04      0.08       242\n",
      "         65       0.00      0.00      0.00        54\n",
      "         66       0.00      0.00      0.00        43\n",
      "         67       1.00      0.02      0.04        45\n",
      "         68       0.62      0.10      0.18       124\n",
      "         69       0.00      0.00      0.00        36\n",
      "         70       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.59      0.48      0.45      3988\n",
      "\n",
      "Accuracy: \t \t 0.15171440442665224 \t 0.0023752969121140144\n",
      "Hamming: \t \t 0.9649907199069028 \t 0.9473252818574153\n",
      "Precision: \t \t 0.6239534807149107 \t 0.5484009751900187\n",
      "Recall: \t \t 0.6047762545066303 \t 0.6405360134003351\n",
      "F1: \t \t \t 0.6443867404453513 \t 0.4794383149448345\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=10, max_depth=10), Xtrain, Xtest, Ytrain, Ytest, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/uufs/chpc.utah.edu/sys/installdir/python/3.6.3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      1.00      0.68     78288\n",
      "          1       0.27      1.00      0.43     27660\n",
      "          2       0.42      0.67      0.52      6415\n",
      "          3       0.42      0.92      0.58     13673\n",
      "          4       0.63      0.54      0.58      2993\n",
      "          5       0.42      0.82      0.55      7849\n",
      "          6       0.52      0.75      0.62      3550\n",
      "          7       0.86      1.00      0.92      4096\n",
      "          8       0.89      0.87      0.88      3904\n",
      "          9       0.82      0.92      0.86      4168\n",
      "         10       0.79      0.56      0.66      2664\n",
      "         11       0.89      0.86      0.87      3854\n",
      "         12       0.86      0.76      0.81      3017\n",
      "         13       0.81      0.95      0.88      6571\n",
      "         14       0.65      0.79      0.71      4344\n",
      "         15       0.34      1.00      0.51     35407\n",
      "         16       0.84      0.55      0.66      3333\n",
      "         17       0.93      1.00      0.96      4096\n",
      "         18       0.77      0.59      0.67      3392\n",
      "         19       0.47      0.64      0.55      4480\n",
      "         20       0.65      0.92      0.76      3260\n",
      "         21       0.53      0.88      0.66      3776\n",
      "         22       0.45      0.42      0.44      2285\n",
      "         23       0.93      0.85      0.89      2720\n",
      "         24       0.68      0.44      0.53      4018\n",
      "         25       0.42      0.45      0.43      4805\n",
      "         26       0.92      0.07      0.14      2300\n",
      "         27       0.98      0.67      0.80      2528\n",
      "         28       0.84      0.55      0.66      3333\n",
      "         29       0.63      0.50      0.56      3212\n",
      "         30       0.91      0.36      0.51      3276\n",
      "         31       0.92      0.39      0.55      2896\n",
      "         32       0.70      0.37      0.48      3728\n",
      "         33       0.86      0.62      0.72      2841\n",
      "         34       0.45      0.38      0.41      5594\n",
      "         35       0.21      0.93      0.35     14367\n",
      "         36       0.85      0.14      0.24      2588\n",
      "         37       0.83      0.52      0.64      4714\n",
      "         38       0.94      0.05      0.09      3256\n",
      "         39       0.91      0.01      0.01      3274\n",
      "         40       0.83      0.80      0.81      2560\n",
      "         41       0.98      0.16      0.28      2432\n",
      "         42       0.26      0.90      0.40     14869\n",
      "         43       0.57      0.82      0.67      4366\n",
      "         44       0.28      0.88      0.42      7706\n",
      "         45       0.72      0.86      0.79      3488\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.72      0.08      0.15      3103\n",
      "         48       0.73      0.08      0.15      3072\n",
      "         49       0.62      0.36      0.45      6704\n",
      "         50       0.97      0.03      0.05      2544\n",
      "         51       0.42      1.00      0.59     56630\n",
      "         52       0.40      0.27      0.32      5449\n",
      "         53       0.64      0.25      0.36      3217\n",
      "         54       0.74      0.55      0.63      6439\n",
      "         55       0.72      0.76      0.74      2992\n",
      "         56       0.72      0.77      0.74      2886\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.92      0.68      0.78      2576\n",
      "         59       0.26      0.84      0.40      9926\n",
      "         60       0.80      0.05      0.09      8331\n",
      "         61       0.77      0.40      0.53      3462\n",
      "         62       0.81      0.87      0.84      3296\n",
      "         63       0.68      0.49      0.57      2284\n",
      "         64       0.45      0.83      0.59      4228\n",
      "         65       0.59      0.74      0.66      2560\n",
      "         66       0.55      0.78      0.64      3380\n",
      "         67       0.63      0.67      0.65      3280\n",
      "         68       0.49      0.85      0.62      4192\n",
      "         69       0.50      0.72      0.59      3846\n",
      "         70       0.53      0.44      0.48      2892\n",
      "\n",
      "avg / total       0.53      0.79      0.56    485235\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94       753\n",
      "          1       0.72      1.00      0.84       588\n",
      "          2       0.08      0.26      0.12        39\n",
      "          3       0.34      0.60      0.43       202\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.65      0.73      0.68       350\n",
      "          6       0.17      0.03      0.05        69\n",
      "          7       0.00      0.00      0.00         3\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         9\n",
      "         11       0.37      0.10      0.16        68\n",
      "         12       0.60      0.06      0.10       107\n",
      "         13       0.13      0.73      0.22        15\n",
      "         14       0.87      0.78      0.82       327\n",
      "         15       0.02      1.00      0.04        15\n",
      "         16       0.02      0.11      0.03         9\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       1.00      1.00      1.00         1\n",
      "         22       1.00      1.00      1.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         0\n",
      "         28       0.02      0.11      0.03         9\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         32       0.00      0.00      0.00         1\n",
      "         33       0.02      0.11      0.03         9\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      1.00      0.01         1\n",
      "         36       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         0\n",
      "         39       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.47      0.36      0.41        64\n",
      "         43       0.40      0.21      0.27        29\n",
      "         44       0.45      0.17      0.25        53\n",
      "         45       0.08      0.11      0.09         9\n",
      "         46       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         4\n",
      "         48       0.00      0.00      0.00         2\n",
      "         49       0.00      0.00      0.00        75\n",
      "         50       0.00      0.00      0.00         0\n",
      "         51       0.48      1.00      0.65       401\n",
      "         52       0.06      0.01      0.02        67\n",
      "         53       0.00      0.00      0.00        10\n",
      "         54       0.00      0.00      0.00        23\n",
      "         55       0.50      0.19      0.27        16\n",
      "         56       0.50      0.43      0.46         7\n",
      "         57       0.00      0.00      0.00         0\n",
      "         58       0.02      1.00      0.03         1\n",
      "         59       0.04      0.47      0.07        15\n",
      "         60       0.00      0.00      0.00        11\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.02      0.04      0.03        23\n",
      "         63       0.00      0.00      0.00        12\n",
      "         64       0.49      0.11      0.18       242\n",
      "         65       0.04      0.02      0.03        54\n",
      "         66       0.25      0.60      0.36        43\n",
      "         67       0.35      0.31      0.33        45\n",
      "         68       0.24      0.31      0.27       124\n",
      "         69       0.11      0.08      0.10        36\n",
      "         70       0.06      0.09      0.07        23\n",
      "\n",
      "avg / total       0.56      0.65      0.57      3988\n",
      "\n",
      "Accuracy: \t \t 0.053704155592341735 \t 0.0011876484560570072\n",
      "Hamming: \t \t 0.9427168244683465 \t 0.9178180723294638\n",
      "Precision: \t \t 0.5540534384100232 \t 0.5137087993665248\n",
      "Recall: \t \t 0.42678035890146027 \t 0.4243663123466885\n",
      "F1: \t \t \t 0.7894937504508125 \t 0.6507021063189569\n"
     ]
    }
   ],
   "source": [
    "predict(RandomForestClassifier(n_estimators=10, max_depth=10), Xtrain, Xtest, Ytrain, Ytest, threshold=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
